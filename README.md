# brivasprime
A swift Python Proof Of Human Gateway using MediaPipe
BioGuard Secure GatewayBioGuard is a high-security, biometric liveness detection gateway designed for mobile and web applications. It prevents spoofing attacks (like holding up a photo) by challenging the user to perform random "motion proofs" (blinking, smiling, turning the head) before verifying their identity.üèó ArchitectureThe system uses a split-architecture for maximum security and responsiveness:The Brain (Python Backend):Framework: FastAPI (High-performance Async API).Core AI: Google MediaPipe (Neural Network for Face Mesh) & OpenCV.Logic: Calculates Eye Aspect Ratio (EAR), Mouth Aspect Ratio (MAR), and Head Pose (Euler Angles) to mathematically verify human movement.Extensibility: Ready to plug into Vector Databases (Milvus/Pinecone) or DeepFace for 1:N identity matching.The Face (Frontend Gateway):Framework: React (via Babel Standalone for portability).Client-Side AI: MediaPipe Tasks Vision (WASM) for real-time UI feedback.UI: Tailwind CSS for a cinematic, dark-mode "CyberSec" aesthetic.üöÄ Getting StartedPrerequisitesPython 3.9+A webcam1. Backend Setup (The Neural Engine)Clone the repository and navigate to the project folder.Install dependencies:pip install fastapi uvicorn opencv-python mediapipe numpy pydantic multipart
Run the API:uvicorn biometric_engine:app --reload
The API will be live at http://localhost:80002. Frontend Setup (The Mobile Gateway)Since the frontend is a standalone HTML file for this demo:Open biometric_gateway.html in any modern web browser (Chrome/Edge/Safari).Allow Camera Access when prompted.The app will initialize the Neural Engine (WASM) and begin the authentication loop.üß™ API EndpointsMethodEndpointDescriptionGET/challenge/newReturns a random challenge (e.g., blink, smile, turn_left) with an ID.POST/verify/livenessUpload a captured frame + Challenge ID. Returns { verified: true, confidence: 0.99 }.üõ° Security LogicBlink Detection: Uses Eye Aspect Ratio (EAR). If EAR drops below 0.21, eyes are closed.Smile Detection: Uses Mouth Aspect Ratio (MAR). Checks distance between lip corners.Head Pose: Uses cv2.solvePnP to map 2D facial landmarks to a 3D generic face model, calculating Yaw, Pitch, and Roll.ü§ù ContributingFork the ProjectCreate your Feature Branch (git checkout -b feature/AmazingFeature)Commit your Changes (git commit -m 'Add some AmazingFeature')Push to the Branch (git push origin feature/AmazingFeature)Open a Pull Request
